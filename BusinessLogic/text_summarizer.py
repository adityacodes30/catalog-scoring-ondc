# -*- coding: utf-8 -*-
"""text_summarizer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13g4RgUc8rdVVPPoiYfKkuqtJLMjm3BOW
"""

#pip install transformers datasets evaluate rouge_score

#pip install transformers datasets evaluate rouge_score

from transformers import AutoTokenizer, T5ForConditionalGeneration

def text_summarizer(input_text, model_name="t5-small"):
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = T5ForConditionalGeneration.from_pretrained(model_name)
    input_ids = tokenizer(
        "summarize: " + input_text,
        return_tensors="pt"
    ).input_ids
    outputs = model.generate(input_ids, max_length=50, num_beams=2, early_stopping=True)
    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return summary

input_text = "This Owl API uses various word2vec models and advanced text clustering techniques to create a better granularity compared to the industry standards. In fact, it uses the largest word2vec English model created by spaCy (i.e., en-core-web-lg) for the general context and uses one of the word2vec models created at Stanford University (i.e., glove-wiki-gigaword-300) for the news context."
summary = text_summarizer(input_text)
print("Summary:")
print(summary)

